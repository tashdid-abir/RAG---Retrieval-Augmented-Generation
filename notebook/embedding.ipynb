{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c3fc48",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tashd\\miniconda3\\envs\\RAG\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Import document loaders for loading PDF files from directories\n",
    "from langchain_community.document_loaders import PyPDFLoader, DirectoryLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4be90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize DirectoryLoader to load all PDF files from the pdf_files directory\n",
    "directory = DirectoryLoader (\n",
    "    \"../data/pdf_files\",\n",
    "    loader_cls=PyPDFLoader,\n",
    "    glob='**/*.pdf',\n",
    "    show_progress=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f8a21e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:06<00:00,  2.32s/it]\n"
     ]
    }
   ],
   "source": [
    "# Load all PDF documents from the directory\n",
    "documents = directory.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0b7c27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'producer': 'iText 4.2.0 by 1T3XT', 'creator': 'PyPDF', 'creationdate': '2026-01-21T22:02:52-08:00', 'moddate': '2026-01-21T22:02:53-08:00', 'subject': 'ACM Trans. Softw. Eng. Methodol. 0.0', 'title': 'Large Language Models for Constructing and Optimizing Machine Learning Workflows: A Survey', 'source': '..\\\\data\\\\pdf_files\\\\Constructing and Optimizing Machine.pdf', 'total_pages': 45, 'page': 0, 'page_label': '1'}, page_content='. \\n. \\nLatest updates: h\\ue03cps://dl.acm.org/doi/10.1145/3773084\\n. \\n. \\nRESEARCH-ARTICLE\\nLarge Language Models for Constructing and Optimizing Machine\\nLearning Workflows: A Survey\\nYANG GU, Shanghai Jiao Tong University, Shanghai, China\\n. \\nHENGYU YOU, Shanghai Jiao Tong University, Shanghai, China\\n. \\nJIAN CAO, Shanghai Jiao Tong University, Shanghai, China\\n. \\nMURAN YU, Stanford University, Stanford, CA, United States\\n. \\nHAORAN FAN, Shanghai Jiao Tong University, Shanghai, China\\n. \\nSHIYOU QIAN, Shanghai Jiao Tong University, Shanghai, China\\n. \\n. \\n. \\nOpen Access Support provided by:\\n. \\nShanghai Jiao Tong University\\n. \\nStanford University\\n. \\nPDF Download\\n3773084.pdf\\n21 January 2026\\nTotal Citations: 3\\nTotal Downloads: 488\\n. \\n. \\nAccepted: 20 October 2025\\nRevised: 23 August 2025\\nReceived: 11 February 2025\\n. \\n. \\nCitation in BibTeX format\\n. \\n. \\nACM Transactions on So\\ue039ware Engineering and Methodology\\nh\\ue03cps://doi.org/10.1145/3773084\\nEISSN: 1557-7392\\n.')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the first document to inspect its structure\n",
    "documents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ec17b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source : ..\\data\\pdf_files\\Constructing and Optimizing Machine.pdf\n",
      "Subject : ACM Trans. Softw. Eng. Methodol. 0.0\n",
      "Total page : 45\n",
      "\n",
      "Content preview : . \n",
      ". \n",
      "Latest updates: hps://dl.acm.org/doi/10.1145/3773084\n",
      ". \n",
      ". \n",
      "RESEARCH-ARTICLE\n",
      "Large Language Models for Constructing and Optimizing Machine\n",
      "Learning Workflows: A Survey\n",
      "YANG GU, Shanghai Jiao Tong University, Shanghai, China\n",
      ". \n",
      "HENGYU YOU, Shanghai Jiao Tong University, Shanghai, China\n",
      ". \n",
      "JIAN CAO, Shanghai Jiao Tong University, Shanghai, China\n",
      ". \n",
      "MURAN YU, Stanford University, Stanford, CA, United States\n",
      ". \n",
      "HAORAN FAN, Shanghai Jiao Tong University, Shanghai, China\n",
      ". \n",
      "SHIYOU QIAN, Shanghai\n"
     ]
    }
   ],
   "source": [
    "# Extract and display metadata and content preview from the first document\n",
    "doc = documents[0]\n",
    "\n",
    "print(f\"Source : {doc.metadata.get('source')}\")  # File path of the document\n",
    "print(f\"Subject : {doc.metadata.get('subject')}\")  # PDF subject metadata\n",
    "print(f\"Total page : {doc.metadata.get('total_pages')}\")  # Total pages in PDF\n",
    "print(f\"\\nContent preview : {doc.page_content[:500]}\")  # First 500 characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe9cc93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries for embeddings generation\n",
    "import numpy as np\n",
    "from typing import List, Dict, Any, Tuple\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eea4bce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Embedding Model : all-MiniLM-L6-v2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading weights: 100%|██████████| 103/103 [00:00<00:00, 823.56it/s, Materializing param=pooler.dense.weight]                             \n",
      "BertModel LOAD REPORT from: sentence-transformers/all-MiniLM-L6-v2\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "Notes:\n",
      "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding Model Loaded Successfully. Embedding Dimension : 384\n",
      "Generating embedding for 170 texts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 6/6 [00:05<00:00,  1.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated embeddings with shape : (170, 384)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.04726338,  0.00032324,  0.0190388 , ...,  0.00690563,\n",
       "         0.00175409,  0.05870934],\n",
       "       [-0.04271643, -0.00851609,  0.00653164, ...,  0.03548166,\n",
       "         0.03997409,  0.03671024],\n",
       "       [-0.02085486, -0.04865111,  0.01053316, ...,  0.04732303,\n",
       "         0.08584597, -0.00469031],\n",
       "       ...,\n",
       "       [-0.07741836, -0.07637152,  0.0221991 , ...,  0.08771045,\n",
       "         0.04401476,  0.09021638],\n",
       "       [-0.13966283,  0.00127   , -0.03442016, ..., -0.01609609,\n",
       "        -0.00326633,  0.03288275],\n",
       "       [ 0.02199661, -0.0140572 , -0.01843296, ...,  0.07923552,\n",
       "         0.07359981,  0.02747879]], shape=(170, 384), dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define EmbeddingManager class to handle loading model and generating embeddings\n",
    "class EmbeddingManager:\n",
    "    def __init__(self, model_name: str = \"all-MiniLM-L6-v2\") -> None:\n",
    "        self.model_name = model_name\n",
    "        self.model = None\n",
    "        self._load_model()  # Initialize model on instantiation\n",
    "\n",
    "\n",
    "    def _load_model(self):\n",
    "        try:\n",
    "            print(f\"Loading Embedding Model : {self.model_name}\")\n",
    "            self.model = SentenceTransformer(self.model_name)  # Downloads model if not cached\n",
    "            print(f\"Embedding Model Loaded Successfully. Embedding Dimension : {self.model.get_sentence_embedding_dimension()}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading model {self.model_name} : {e}\")\n",
    "            raise\n",
    "\n",
    "\n",
    "    def generate_embeddings(self, texts: List[str]) -> np.ndarray:\n",
    "        if not self.model:\n",
    "            raise ValueError(\"Model not loaded\")\n",
    "        \n",
    "        print(f\"Generating embedding for {len(texts)} texts...\")\n",
    "        embeddings = self.model.encode(texts, show_progress_bar=True)  # Convert texts to vectors\n",
    "        print(f\"Generated embeddings with shape : {embeddings.shape}\")\n",
    "        return embeddings\n",
    "\n",
    "# Create EmbeddingManager instance and generate embeddings for all documents\n",
    "embedding_manager = EmbeddingManager()\n",
    "embeddings = embedding_manager.generate_embeddings([d.page_content for d in documents])  # Extract text from each doc\n",
    "embeddings"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RAG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
